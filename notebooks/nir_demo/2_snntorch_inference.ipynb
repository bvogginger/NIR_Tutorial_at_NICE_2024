{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd859325-e192-4084-a587-de1fa73f4f3b",
   "metadata": {},
   "source": [
    "# snnTorch Inference with NIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a208f1b-2ee5-4f21-8055-415048f7523f",
   "metadata": {},
   "source": [
    "## 1. Installation, Imports and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b9e8e3-227a-41bd-9419-a3977057b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snntorch --quiet\n",
    "!pip install tonic --quiet\n",
    "!pip install nir --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fac42a-c066-429e-988c-3f9d18552e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d29dec-4e30-4027-98ca-f43cffa06d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic\n",
    "\n",
    "poker_test = tonic.datasets.POKERDVS(save_to='./data', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c63d7d8-cd37-4d85-91ab-46e39dde58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic.transforms as transforms\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "# time_window\n",
    "frame_transform = tonic.transforms.Compose([tonic.transforms.Denoise(filter_time=10000),\n",
    "                                            tonic.transforms.ToFrame(\n",
    "                                            sensor_size=tonic.datasets.POKERDVS.sensor_size,\n",
    "                                            time_window=1000)\n",
    "                                            ])\n",
    "\n",
    "batch_size = 8\n",
    "cached_testset = DiskCachedDataset(poker_test, transform=frame_transform, cache_path='./cache/pokerdvs/test')\n",
    "test_loader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6977b-446f-4d85-8167-f7df85410421",
   "metadata": {},
   "source": [
    "## 2. Load NIR graph into snnTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd1cdf9-52c0-49b9-a671-c42256c5ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4bda7a2-e786-4469-bbf5-07722ffae33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_model = nir.read(\"nir_model.nir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89143ada-20da-4e4a-ab23-e5cc8ce819f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n"
     ]
    }
   ],
   "source": [
    "net = snn.import_from_nir(nir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0b26bf-1528-4b4c-a9c7-7acaa81f6f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphExecutor(\n",
       "  (fc1): Linear(in_features=2450, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (input): Identity()\n",
       "  (lif1): Synaptic()\n",
       "  (lif2): Synaptic()\n",
       "  (output): Identity()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcd372-a74c-4864-9ee1-2a7ec535a993",
   "metadata": {},
   "source": [
    "**TODO: add some information about the `nirtorch.GraphExecutor`** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b16a6f-195d-4919-a2cb-1875335fe42b",
   "metadata": {},
   "source": [
    "## 3. Run the model with a single batch of data\n",
    "\n",
    "The graph executor can run a single forward step. Let's add the recurrence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588aff50-06e9-4027-90ec-3bc5deb48512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(data):\n",
    "    \"\"\"\n",
    "    apply an input data batch to the snntorch model\n",
    "    \"\"\"\n",
    "    state = None\n",
    "    hid_rec = []\n",
    "    out = []\n",
    "    # init/reset membrane voltage for each run\n",
    "    net.lif1.init_synaptic()\n",
    "    net.lif2.init_synaptic()\n",
    "    \n",
    "    for i, t in enumerate(data):\n",
    "        z, state = net(t.flatten(1), state)\n",
    "        print(i, state)\n",
    "        out.append(z)\n",
    "        hid_rec.append(state)\n",
    "    spk_out = torch.stack(out)\n",
    "    # hid_rec = torch.stack(hid_rec)\n",
    "    return spk_out, hid_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b516468-341c-4890-bc04-ffd3a175b80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0f8aeb-f1df-45b1-b4db-5ae66460e560",
   "metadata": {},
   "source": [
    "Apply to a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adbecf42-6caa-42bf-9711-4ce9931aeb62",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_loader))\n\u001b[0;32m----> 3\u001b[0m spk, hid \u001b[38;5;241m=\u001b[39m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# count the number of spikes for each neuron and assess the winner\u001b[39;00m\n\u001b[1;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m spk\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     10\u001b[0m net\u001b[38;5;241m.\u001b[39mlif2\u001b[38;5;241m.\u001b[39minit_synaptic()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m---> 13\u001b[0m     z, state \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, state)\n\u001b[1;32m     15\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(z)\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/nirtorch/from_nir.py:148\u001b[0m, in \u001b[0;36mGraphExecutor.forward\u001b[0;34m(self, data, old_state)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39melem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m out, new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mold_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst_node\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m new_state\u001b[38;5;241m.\u001b[39mcache[node\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m    156\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/nirtorch/from_nir.py:121\u001b[0m, in \u001b[0;36mGraphExecutor._apply_module\u001b[0;34m(self, node, input_nodes, new_state, old_state, data)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(summed_inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    119\u001b[0m     inputs\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mstack(summed_inputs)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 121\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# If the module is stateful, we know the output is (at least) a tuple\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# HACK to make it work for snnTorch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m is_rsynaptic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnntorch._neurons.rsynaptic.RSynaptic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    125\u001b[0m     node\u001b[38;5;241m.\u001b[39melem\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    126\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nir-demo/lib/python3.10/site-packages/snntorch/_neurons/synaptic.py:257\u001b[0m, in \u001b[0;36mSynaptic.forward\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m    255\u001b[0m         mem \u001b[38;5;241m=\u001b[39m mem \u001b[38;5;241m-\u001b[39m do_reset \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_mechanism_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# reset to zero\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m         mem \u001b[38;5;241m=\u001b[39m mem \u001b[38;5;241m-\u001b[39m \u001b[43mdo_reset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "data, targets = next(iter(test_loader))\n",
    "\n",
    "spk, hid = apply(data)\n",
    "\n",
    "# count the number of spikes for each neuron and assess the winner\n",
    "predictions = spk.sum(axis=0).argmax(axis=-1)\n",
    "print(f\"Predicted classes: {predictions}\")\n",
    "print(f\"Actual classes:    {targets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37736f10-939c-4a84-8ce9-50fb8b93c129",
   "metadata": {},
   "source": [
    "### 4. Measure accuracy for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98934eca-c872-4555-8b1f-7bdefc82f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(model, dataloader):\n",
    "  with torch.no_grad():\n",
    "    # model.eval()  # not needed!\n",
    "    running_length = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for data, targets in iter(dataloader):\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # forward-pass\n",
    "      spk_rec, _ = model(data)\n",
    "      spike_count = spk_rec.sum(0) # batch x num_outputs\n",
    "      _, max_spike = spike_count.max(1)\n",
    "\n",
    "      # correct classes for one batch\n",
    "      num_correct = (max_spike == targets).sum()\n",
    "\n",
    "      # total accuracy\n",
    "      running_length += len(targets)\n",
    "      running_accuracy += num_correct\n",
    "\n",
    "    accuracy = (running_accuracy / running_length)\n",
    "\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f0170-1574-4b5d-a0dd-cd1549c97e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_accuracy(apply, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nir-demo] *",
   "language": "python",
   "name": "conda-env-nir-demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
