{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyNLu56m20JM"
      },
      "source": [
        "# **Neuromorphic Lab**\n",
        "\n",
        "<font size=\"5\"><b>\"Neuromorphic Computing and Engineering\" Ph.D. course</b></font>\n",
        "\n",
        "Prof. G. Urgese, V. Fra\n",
        "\n",
        "<font size=\"3\">*Politecnico di Torino, 2024*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font size=\"2\">The present *draft* notebook is extracted from the material prepared for hands-on coding in a laboratory session of a Ph.D. course at Politecnico di Torino.</font><br>\n",
        "<font size=\"2\">The aim was to show how NIR allows to train a network in some framework and then use it in some other framework. Consequently, and as for the purpose of the course to let students play with neuron models and parameters, the proposed architecture did not undergo optimization but relied on quick training phases after network design.<br></font>\n",
        "\n",
        "<font size=\"2\">NOTE that, at the time of running, `reset_delay=False` turned out to produce an error in `snnTorch` which was not present for the NIR experiments (and which was maybe introduced by some snnTorch update). I did not investigated it and I kept the resulting inconsistency knowing it impacts on the comparison between the two adopted frameworks. Despite this issue, the goal of showing how NIR, at the end of a laboratory session entirely based on `snnTorch`, allows to run the network in a completely new framework was achievable.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJsVu0H2FIol"
      },
      "source": [
        "## Environment set-up for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-qowl4U2xh2"
      },
      "outputs": [],
      "source": [
        "!pip3 freeze > colab_default.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZd73C43kWzt"
      },
      "source": [
        "Load `env_nce24_colab.txt` and the `figures` folder in `./content/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TsLcZs4MJsG"
      },
      "outputs": [],
      "source": [
        "with open('colab_default.txt', 'r') as f:\n",
        "  colab_default = f.readlines()\n",
        "\n",
        "with open('env_nce24_colab.txt', 'r') as f:\n",
        "  env_nce24_colab = f.readlines()\n",
        "\n",
        "with open('nce24_colab.txt', 'w') as f:\n",
        "  for pkg in env_nce24_colab:\n",
        "    if any(pkg.split(\"==\")[0].casefold() in ii.casefold() for ii in colab_default):\n",
        "      pass\n",
        "    else:\n",
        "      f.write(pkg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCnoTQxOMJsG",
        "outputId": "52c9a345-cf5f-452e-8f9e-8ac0e69b8c3a"
      },
      "outputs": [],
      "source": [
        "!pip install -r nce24_colab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NA8boT4kWzu",
        "outputId": "bd35c2c4-29fc-4bcd-eac3-d897ce539e5c"
      },
      "outputs": [],
      "source": [
        "!git clone https://gitlab.com/spinnaker2/py-spinnaker2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cv7SwFtkWzu",
        "outputId": "beb96eb3-9a44-4b11-df17-257ad7d3a136"
      },
      "outputs": [],
      "source": [
        "!pip install -e ./py-spinnaker2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imVSAw8dkWzu"
      },
      "source": [
        "---\n",
        "Remember to include the changes into `snntorch.export_nir.export_to_nir` (path: /usr/local/lib/python3.10/dist-packages/snntorch/export_nir.py) for the `Synaptic` case:\n",
        "\n",
        "lines\n",
        "```\n",
        "# TODO: assert that size of the current layer is correct\n",
        "alpha = module.alpha.detach().numpy()\n",
        "beta = module.beta.detach().numpy()\n",
        "vthr = module.threshold.detach().numpy()\n",
        "```\n",
        "\n",
        "to be replaced with\n",
        "```\n",
        "assert \"n_neurons\" in dir(module), \"The n_neurons attribute must be set for the given module: module.__setattr__('n_neurons',VALUE)\"\n",
        "alpha = np.ones(module.n_neurons) * module.alpha.detach().numpy()\n",
        "beta = np.ones(module.n_neurons) * module.beta.detach().numpy()\n",
        "vthr = np.ones(module.n_neurons) * module.threshold.detach().numpy()\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA-Dun1ikWzu"
      },
      "source": [
        "## Basic settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Remember to include the changes into `snntorch.export_nir.export_to_nir` for the `Synaptic` case:\n",
        "\n",
        "lines\n",
        "```\n",
        "# TODO: assert that size of the current layer is correct\n",
        "alpha = module.alpha.detach().numpy()\n",
        "beta = module.beta.detach().numpy()\n",
        "vthr = module.threshold.detach().numpy()\n",
        "```\n",
        "\n",
        "to be replaced with\n",
        "```\n",
        "assert \"n_neurons\" in dir(module), \"The n_neurons attribute must be set for the given module: module.__setattr__('n_neurons',VALUE)\"\n",
        "alpha = np.ones(module.n_neurons) * module.alpha.detach().numpy()\n",
        "beta = np.ones(module.n_neurons) * module.beta.detach().numpy()\n",
        "vthr = np.ones(module.n_neurons) * module.threshold.detach().numpy()\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8wpfqP3MJsG"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fohzNZo6kWzv"
      },
      "outputs": [],
      "source": [
        "use_seed = True\n",
        "\n",
        "if use_seed:\n",
        "    seed = 42\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "else:\n",
        "    seed = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-PnbqxQkWzv"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0pq1QdFDEH9"
      },
      "source": [
        "### Custom utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNEkKo98DGXk"
      },
      "outputs": [],
      "source": [
        "def create_directory(\n",
        "    directory_path\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Muller-Cleve, Simon F.; Istituto Italiano di Tecnologia - IIT; Event-driven perception in robotics - EDPR; Genova, Italy.\n",
        "    \"\"\"\n",
        "    if os.path.exists(directory_path):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            os.makedirs(directory_path)\n",
        "        except:\n",
        "            # in case another machine created the path meanwhile! :(\n",
        "            return None\n",
        "        return directory_path\n",
        "\n",
        "\n",
        "def train_validation_test_split(\n",
        "    data,\n",
        "    label,\n",
        "    split=[70, 20, 10],\n",
        "    seed=None,\n",
        "    multiple=False,\n",
        "    save_dataset=False,\n",
        "    save_tensor=False,\n",
        "    labels_type=None,\n",
        "    labels_mapping=None,\n",
        "    save_name=None,\n",
        "    save_path=None\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Creates train-validation-test splits using the sklearn train_test_split() twice.\n",
        "    Can be used either to prepare \"ready-to-use\" splits or to create and store splits.\n",
        "\n",
        "    If multiple splits are not needed and no saving option is set, the lists x_train, y_train, x_val, y_val, x_test, y_test are returned (without labels mapping).\n",
        "\n",
        "    Function accepts lists, arrays, and tensor.\n",
        "    Default split: [training: 70, validation: 20, test: 10]\n",
        "\n",
        "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
        "    Muller-Cleve, Simon F.; Istituto Italiano di Tecnologia - IIT; Event-driven perception in robotics - EDPR; Genova, Italy.\n",
        "    \"\"\"\n",
        "\n",
        "    if multiple:\n",
        "        if (not save_dataset) & (not save_tensor):\n",
        "            raise ValueError(\"Multiple train-val splits are created but no saving option is enabled.\")\n",
        "\n",
        "    if save_dataset | save_tensor:\n",
        "        if (save_path == None) | (save_name == None):\n",
        "            raise ValueError(\"Check a file name and a path are provided to save the datasets.\")\n",
        "        filename_prefix = save_path + save_name\n",
        "        create_directory(save_path)\n",
        "\n",
        "    # do some sanity checks first\n",
        "    if len(split) != 3:\n",
        "        raise ValueError(\n",
        "            f\"Split dimensions are wrong. Expected 3 but got {len(split)}. Please provide split in the form [train size, test size, validation size].\")\n",
        "    if min(split) == 0.0:\n",
        "        raise ValueError(\n",
        "            \"Found entry 0.0. If you want to use only perfrom a two-folded split, use the sklearn train_test_split function only please.\")\n",
        "    if sum(split) > 99.0:\n",
        "        split = [x/100 for x in split]\n",
        "    if sum(split) < 0.99:\n",
        "        raise ValueError(\"Please use a split summing up to 1, or 100%.\")\n",
        "\n",
        "    train, val, test = split\n",
        "    split_1 = test\n",
        "    split_2 = 1 - train/(train+val)\n",
        "\n",
        "    x_trainval, x_test, y_trainval, y_test = train_test_split(\n",
        "        data, label, test_size=split_1, shuffle=True, stratify=label, random_state=seed)\n",
        "\n",
        "\n",
        "    if save_dataset: # Save the test split\n",
        "        filename_test = filename_prefix + \"_test\"\n",
        "        # xs test\n",
        "        with open(f\"{filename_test}.pkl\", 'wb') as handle:\n",
        "            pkl.dump(np.array(x_test, dtype=object), handle,\n",
        "                        protocol=pkl.HIGHEST_PROTOCOL)\n",
        "        # ys test\n",
        "        with open(f\"{filename_test}_label.pkl\", 'wb') as handle:\n",
        "            pkl.dump(np.array(y_test, dtype=object), handle,\n",
        "                        protocol=pkl.HIGHEST_PROTOCOL)\n",
        "\n",
        "    if save_tensor: # Save the test split\n",
        "        filename_test = filename_prefix + \"_ds_test\"\n",
        "        x_test = torch.as_tensor(np.array(x_test), dtype=torch.float)\n",
        "        if labels_type == str:\n",
        "            labels_test = torch.as_tensor(value2index(\n",
        "                y_test, labels_mapping), dtype=torch.long)\n",
        "        else:\n",
        "            labels_test = torch.as_tensor(y_test, dtype=torch.long)\n",
        "        ds_test = TensorDataset(x_test, labels_test)\n",
        "        torch.save(ds_test, \"{}.pt\".format(filename_test))\n",
        "\n",
        "    if multiple:\n",
        "\n",
        "        for ii in range(10):\n",
        "\n",
        "            x_train, x_val, y_train, y_val = train_test_split(\n",
        "                x_trainval, y_trainval, test_size=split_2, shuffle=True, stratify=y_trainval, random_state=seed)\n",
        "\n",
        "            if save_dataset:\n",
        "\n",
        "                filename_train = filename_prefix + \"_train\"\n",
        "                filename_val = filename_prefix + \"_val\"\n",
        "\n",
        "                # xs training\n",
        "                with open(f\"{filename_train}_{ii}.pkl\", 'wb') as handle:\n",
        "                    pkl.dump(np.array(x_train, dtype=object), handle,\n",
        "                                protocol=pkl.HIGHEST_PROTOCOL)\n",
        "                # ys training\n",
        "                with open(f\"{filename_train}_{ii}_label.pkl\", 'wb') as handle:\n",
        "                    pkl.dump(np.array(y_train, dtype=object), handle,\n",
        "                                protocol=pkl.HIGHEST_PROTOCOL)\n",
        "\n",
        "                # xs validation\n",
        "                with open(f\"{filename_val}_{ii}.pkl\", 'wb') as handle:\n",
        "                    pkl.dump(np.array(x_val, dtype=object), handle,\n",
        "                                protocol=pkl.HIGHEST_PROTOCOL)\n",
        "                # ys validation\n",
        "                with open(f\"{filename_val}_{ii}_label.pkl\", 'wb') as handle:\n",
        "                    pkl.dump(np.array(y_val, dtype=object), handle,\n",
        "                                protocol=pkl.HIGHEST_PROTOCOL)\n",
        "\n",
        "            if save_tensor:\n",
        "\n",
        "                filename_train = filename_prefix + \"_ds_train\"\n",
        "                filename_val = filename_prefix + \"_ds_val\"\n",
        "\n",
        "                x_train = torch.as_tensor(np.array(x_train), dtype=torch.float)\n",
        "                if labels_type == str:\n",
        "                    labels_train = torch.as_tensor(value2index(\n",
        "                        y_train, labels_mapping), dtype=torch.long)\n",
        "                else:\n",
        "                    labels_train = torch.as_tensor(y_train, dtype=torch.long)\n",
        "\n",
        "                x_validation = torch.as_tensor(\n",
        "                    np.array(x_val), dtype=torch.float)\n",
        "                if labels_type == str:\n",
        "                    labels_validation = torch.as_tensor(value2index(\n",
        "                        y_val, labels_mapping), dtype=torch.long)\n",
        "                else:\n",
        "                    labels_validation = torch.as_tensor(y_val, dtype=torch.long)\n",
        "\n",
        "                ds_train = TensorDataset(x_train, labels_train)\n",
        "                ds_val = TensorDataset(x_validation, labels_validation)\n",
        "\n",
        "                torch.save(ds_train, \"{}_{}.pt\".format(filename_train,ii))\n",
        "                torch.save(ds_val, \"{}_{}.pt\".format(filename_val,ii))\n",
        "\n",
        "    else:\n",
        "\n",
        "        x_train, x_val, y_train, y_val = train_test_split(\n",
        "            x_trainval, y_trainval, test_size=split_2, shuffle=True, stratify=y_trainval, random_state=seed)\n",
        "\n",
        "        if save_dataset:\n",
        "\n",
        "            filename_train = filename_prefix + \"_train\"\n",
        "            filename_val = filename_prefix + \"_val\"\n",
        "\n",
        "            # xs training\n",
        "            with open(f\"{filename_train}.pkl\", 'wb') as handle:\n",
        "                pkl.dump(np.array(x_train, dtype=object), handle,\n",
        "                            protocol=pkl.HIGHEST_PROTOCOL)\n",
        "            # ys training\n",
        "            with open(f\"{filename_train}_label.pkl\", 'wb') as handle:\n",
        "                pkl.dump(np.array(y_train, dtype=object), handle,\n",
        "                            protocol=pkl.HIGHEST_PROTOCOL)\n",
        "\n",
        "            # xs validation\n",
        "            with open(f\"{filename_val}.pkl\", 'wb') as handle:\n",
        "                pkl.dump(np.array(x_val, dtype=object), handle,\n",
        "                            protocol=pkl.HIGHEST_PROTOCOL)\n",
        "            # ys validation\n",
        "            with open(f\"{filename_val}_label.pkl\", 'wb') as handle:\n",
        "                pkl.dump(np.array(y_val, dtype=object), handle,\n",
        "                            protocol=pkl.HIGHEST_PROTOCOL)\n",
        "\n",
        "        if save_tensor:\n",
        "\n",
        "            filename_train = filename_prefix + \"_ds_train\"\n",
        "            filename_val = filename_prefix + \"_ds_val\"\n",
        "\n",
        "            x_train = torch.as_tensor(np.array(x_train), dtype=torch.float)\n",
        "            if labels_type == str:\n",
        "                labels_train = torch.as_tensor(value2index(\n",
        "                    y_train, labels_mapping), dtype=torch.long)\n",
        "            else:\n",
        "                labels_train = torch.as_tensor(y_train, dtype=torch.long)\n",
        "\n",
        "            x_validation = torch.as_tensor(\n",
        "                np.array(x_val), dtype=torch.float)\n",
        "            if labels_type == str:\n",
        "                labels_validation = torch.as_tensor(value2index(\n",
        "                    y_val, labels_mapping), dtype=torch.long)\n",
        "            else:\n",
        "                labels_validation = torch.as_tensor(y_val, dtype=torch.long)\n",
        "\n",
        "            ds_train = TensorDataset(x_train, labels_train)\n",
        "            ds_val = TensorDataset(x_validation, labels_validation)\n",
        "\n",
        "            torch.save(ds_train, filename_train)\n",
        "            torch.save(ds_val, filename_val)\n",
        "\n",
        "        return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "\n",
        "def value2index(\n",
        "    entry,\n",
        "    dictionary\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
        "    \"\"\"\n",
        "\n",
        "    if (type(entry) != list) & (type(entry) != np.ndarray):\n",
        "\n",
        "        idx = [list(dictionary.values()).index(entry)]\n",
        "\n",
        "    else:\n",
        "\n",
        "        idx = [list(dictionary.values()).index(e) for e in entry]\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWFH_RlnkWzw"
      },
      "source": [
        "### Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJL-VkN4kWzw"
      },
      "outputs": [],
      "source": [
        "def training_loop(\n",
        "    dataset,\n",
        "    batch_size,\n",
        "    net,\n",
        "    optimizer,\n",
        "    loss_fn):\n",
        "    \"\"\"\n",
        "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
        "    \"\"\"\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    batch_loss = []\n",
        "    batch_acc = []\n",
        "\n",
        "    for data, labels in tqdm(train_loader):\n",
        "\n",
        "      data = data#.to(device)\n",
        "      labels = labels#.to(device)\n",
        "\n",
        "      net.train()\n",
        "      spk_rec, _, _ = net(data)\n",
        "\n",
        "      # Training loss\n",
        "      loss_val = loss_fn(spk_rec, labels)\n",
        "      batch_loss.append(loss_val.detach().cpu().item())\n",
        "\n",
        "      # Training accuracy\n",
        "      act_total_out = torch.sum(spk_rec, 0)  # sum over time\n",
        "      _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
        "      batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
        "\n",
        "      # Gradient calculation + weight update\n",
        "      optimizer.zero_grad()\n",
        "      loss_val.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    epoch_loss = np.mean(batch_loss)\n",
        "    epoch_acc = np.mean(batch_acc)\n",
        "\n",
        "    return [epoch_loss, epoch_acc]\n",
        "\n",
        "\n",
        "def val_test_loop(\n",
        "    dataset,\n",
        "    batch_size,\n",
        "    net,\n",
        "    loss_fn,\n",
        "    shuffle=True,\n",
        "    label_probabilities=False,\n",
        "    return_spikes=False):\n",
        "    \"\"\"\n",
        "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "\n",
        "      loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
        "\n",
        "      batch_loss = []\n",
        "      batch_acc = []\n",
        "\n",
        "      for data, labels in tqdm(loader):\n",
        "          data = data#.to(device)\n",
        "          labels = labels#.to(device)\n",
        "\n",
        "          spk_out, _, _ = net(data)\n",
        "\n",
        "          # Loss\n",
        "          loss_val = loss_fn(spk_out, labels)\n",
        "          batch_loss.append(loss_val.detach().cpu().item())\n",
        "\n",
        "          # Accuracy\n",
        "          act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
        "          _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
        "          batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
        "\n",
        "      if label_probabilities:\n",
        "          log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "          log_p_y = log_softmax_fn(act_total_out)\n",
        "          if return_spikes:\n",
        "            return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y), spk_out.detach().cpu().numpy()\n",
        "          else:\n",
        "            return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
        "      else:\n",
        "        if return_spikes:\n",
        "          return [np.mean(batch_loss), np.mean(batch_acc)], spk_out.detach().cpu().numpy()\n",
        "        else:\n",
        "          return [np.mean(batch_loss), np.mean(batch_acc)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Link(s) to the folder with raw Braille data\n",
        "\n",
        "braille_nir_train_link = \"https://drive.google.com/file/d/1xjT8I-Y70yMV_HcKbWmalqXu1YaJMZEg/view?usp=sharing\"\n",
        "braille_nir_val_link = \"https://drive.google.com/file/d/1m6XPpmddEmp0HrO4WUBwQQZn0jnO1MkA/view?usp=sharing\"\n",
        "braille_nir_test_link = \"https://drive.google.com/file/d/1KwqB4U5LnPhFvmn1GJoHYSwrX9Ccs5_8/view?usp=sharing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_folder = \"./data/Braille\" \n",
        "create_directory(data_folder)\n",
        "files_in_data_folder = os.listdir(data_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"ds_train_nir.pt\" in files_in_data_folder:\n",
        "    ds_train = torch.load(os.path.join(data_folder,\"ds_train_nir.pt\"), map_location=device)\n",
        "else:\n",
        "    ds_train = torch.load(gdown.download(braille_nir_train_link, output=os.path.join(data_folder,\"ds_train_nir.pt\"), fuzzy=True), map_location=device)\n",
        "\n",
        "if \"ds_val_nir.pt\" in files_in_data_folder:\n",
        "    ds_val = torch.load(os.path.join(data_folder,\"ds_val_nir.pt\"), map_location=device)\n",
        "else:\n",
        "    ds_val = torch.load(gdown.download(braille_nir_val_link, output=os.path.join(data_folder,\"ds_val_nir.pt\"), fuzzy=True), map_location=device)\n",
        "\n",
        "if \"ds_test_nir.pt\" in files_in_data_folder:\n",
        "    ds_test = torch.load(os.path.join(data_folder,\"ds_test_nir.pt\"), map_location=device)\n",
        "else:\n",
        "    ds_test = torch.load(gdown.download(braille_nir_test_link, output=os.path.join(data_folder,\"ds_test_nir.pt\"), fuzzy=True), map_location=device)\n",
        "\n",
        "num_steps = next(iter(ds_test))[0].shape[0]\n",
        "letter_written_nir = ['Space', 'A', 'E', 'I', 'O', 'U', 'Y']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UxA8MFmE569"
      },
      "outputs": [],
      "source": [
        "from itertools import islice\n",
        "\n",
        "import nir\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import export_nir\n",
        "from snntorch import functional as SF\n",
        "\n",
        "from spinnaker2 import brian2_sim, s2_nir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVW1Ume36g1c"
      },
      "source": [
        "## Neuromorphic Intermediate Representation (NIR)\n",
        "\n",
        "<center>\n",
        "<img src=\"./figures/logo_NIR_dark.png\" alt=\"drawing\" width=\"700\"/>\n",
        "</center><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align:center\">    \n",
        "  From <a href=\"https://arxiv.org/abs/2311.14641\">\"Neuromorphic Intermediate Representation: A Unified Instruction Set for Interoperable Brain-Inspired Computing\"</a>\n",
        "</div><br>\n",
        "\n",
        "<center>\n",
        "<img src=\"./figures/NIR_arXiv_reduced.png\" alt=\"drawing\" width=\"1400\"/>\n",
        "</center><br>\n",
        "\n",
        "<div style=\"text-align:center\">    \n",
        "  <a href=\"https://github.com/neuromorphs/NIR/tree/main\">GitHub repository</a>\n",
        "</div><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqf1jX6HkWz4"
      },
      "source": [
        "<img src=\"./figures/NIR_taxonomy.png\" alt=\"drawing\" width=\"700\" style=\"float: right; margin-left: 10px; margin-right: 20px\"/>\n",
        "\n",
        "*Spiking neural networks and neuromorphic hardware platforms that emulate neural dynamics are slowly gaining momentum and entering main-stream usage. Despite a well-established mathematical foundation for neural dynamics,* **the implementation details vary greatly across different platforms.** *Correspondingly, there are a plethora of software and hardware implementations with their own unique technology stacks. Consequently, neuromorphic systems typically diverge from the expected computational model, which challenges the reproducibility and reliability across platforms. Additionally,* **most neuromorphic hardware is limited by its access via a single software frameworks with a limited set of training procedures.** *Here, we establish a common reference-frame for computations in neuromorphic systems, dubbed the Neuromorphic Intermediate Representation (NIR). NIR defines a set of computational primitives as idealized continuous-time hybrid systems that can be composed into graphs and mapped to and from various neuromorphic technology stacks. By abstracting away assumptions around discretization and hardware constraints, NIR faithfully captures the fundamental computation, while simultaneously exposing the exact differences between the evaluated implementation and the idealized mathematical formalism.<br>* \n",
        "\n",
        "<img src=\"./figures/NIR_at-a-glance.png\" alt=\"drawing\" width=\"500\" style=\"float: right; margin-left: 10px; margin-right: 20px\"/>\n",
        "\n",
        "*In the paper, three NIR graphs are reproduced across* **7 neuromorphic simulators and 4 hardware platforms,** *demonstrating support for an unprecedented number of neuromorphic systems:* \n",
        "\n",
        "**With NIR, we decouple the evolution of neuromorphic hardware and software, ultimately increasing the interoperability between platforms and improving accessibility to neuromorphic technologies.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./figures/NIR_primitives_table.png\" alt=\"drawing\" width=\"450\" style=\"float: left; margin-right: 10px\"/>\n",
        "\n",
        "<img src=\"./figures/NIR_higher-order.png\" alt=\"drawing\" width=\"450\" style=\"float: right; margin-left: 10px; margin-right: 20px\"/>\n",
        "\n",
        "NIR defines **11 computational primitives and 3 higher-order primitives**.<br> \n",
        "We define common neuromorphic components like the linear map, leaky integrator, and spike threshold function, but we further included mathematical primitives such as the affine map and convolution. The input and output nodes serve to disambiguate the entries and exits of a graph.<br>\n",
        "\n",
        "The 11 primitives in NIR are “fundamental” in the sense that the backends implementing the primitives are required to approximate the computation of the idealized description as closely as possible within the limitations of the platform. Any given platform is not expected to implement the full specification. This is particularly true for functionally specialized hardware, where hardware restrictions render certain functional primitives impossible.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"text-align:center\">    \n",
        "  <font size=\"5\"><b>The NIR experiments</b></font>\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "<img src=\"./figures/NIR_experiments.png\" alt=\"drawing\" width=\"700\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMjqhHyHkWz4"
      },
      "source": [
        "### Build and train a SNN in snnTorch for Braille classification and test it in a different framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./figures/2L_FC_R-a2a.png\" alt=\"drawing\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJmNzrobkWz4"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "    \"input_size\"     :    12,\n",
        "    \"nb_hidden\"      :    100,\n",
        "    \"alpha_r\"        :    0.3,\n",
        "    \"beta_r\"         :    0.5,\n",
        "    \"thr_r\"          :    0.8,\n",
        "    \"alpha_out\"      :    0.2,\n",
        "    \"beta_out\"       :    0.8,\n",
        "    \"thr_out\"        :    1.0,\n",
        "    \"lr\"             :    0.0005,\n",
        "    \"reset\"          :    \"zero\",\n",
        "    \"reset_delay\"    :    True\n",
        "}\n",
        "\n",
        "model_name = \"nce24_braille_rsnn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yym1rqzGkWz5"
      },
      "outputs": [],
      "source": [
        "def model_build(settings, num_steps, device):\n",
        "\n",
        "    ### Network structure (input data --> recurrent -> output)\n",
        "    input_channels = int(settings[\"input_size\"])\n",
        "    num_hidden = int(settings[\"nb_hidden\"])\n",
        "    num_outputs = int(len(letter_written_nir))\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            ##### Initialize layers #####\n",
        "            ### Recurrent layer\n",
        "            self.fc1 = nn.Linear(input_channels, num_hidden)\n",
        "            self.lif1 = snn.RSynaptic(alpha=settings[\"alpha_r\"], beta=settings[\"beta_r\"], threshold=settings[\"thr_r\"], linear_features=num_hidden, reset_mechanism=settings[\"reset\"], reset_delay=settings[\"reset_delay\"])\n",
        "            ### Output layer\n",
        "            self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "            self.lif2 = snn.Synaptic(alpha=settings[\"alpha_out\"], beta=settings[\"beta_out\"], threshold=settings[\"thr_out\"], reset_mechanism=settings[\"reset\"], reset_delay=settings[\"reset_delay\"])\n",
        "            self.lif2.__setattr__(\"n_neurons\",num_outputs)\n",
        "\n",
        "        def forward(self, x):\n",
        "\n",
        "            ##### Initialize hidden states at t=0 #####\n",
        "            spk1, syn1, mem1 = self.lif1.init_rsynaptic()\n",
        "            syn2, mem2 = self.lif2.init_synaptic()\n",
        "\n",
        "            # Record the final layer\n",
        "            spk2_rec = []\n",
        "            syn2_rec = []\n",
        "            mem2_rec = []\n",
        "\n",
        "            for step in range(num_steps):\n",
        "                ### Recurrent layer\n",
        "                cur1 = self.fc1(x[:,step,:])\n",
        "                spk1, syn1, mem1 = self.lif1(cur1, spk1, syn1, mem1)\n",
        "                ### Output layer\n",
        "                cur2 = self.fc2(spk1)\n",
        "                spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "                spk2_rec.append(spk2)\n",
        "                syn2_rec.append(syn2)\n",
        "                mem2_rec.append(mem2)\n",
        "\n",
        "            return torch.stack(spk2_rec, dim=0), torch.stack(syn2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "    return Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXyTl7EGkWz5"
      },
      "outputs": [],
      "source": [
        "net = model_build(settings, num_steps, device)\n",
        "\n",
        "loss_fn = SF.ce_count_loss()\n",
        "\n",
        "log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=settings[\"lr\"])\n",
        "\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSUuuT3xkWz5"
      },
      "source": [
        "#### Train the network (with validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn6YMJX-kWz5",
        "outputId": "cde9d27b-bc2d-439e-d915-5a1f16bfa76a"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "training_results = []\n",
        "validation_results = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  train_loss, train_acc = training_loop(ds_train, batch_size, net, optimizer, loss_fn)\n",
        "  val_loss, val_acc = val_test_loop(ds_val, batch_size, net, loss_fn)\n",
        "\n",
        "  training_results.append([train_loss, train_acc])\n",
        "  validation_results.append([val_loss, val_acc])\n",
        "\n",
        "  print(\"Epoch {}/{}: \\n\\ttraining loss: {} \\n\\tvalidation loss: {} \\n\\ttraining accuracy: {}% \\n\\tvalidation accuracy: {}%\".format(epoch+1, num_epochs, training_results[-1][0], validation_results[-1][0], np.round(training_results[-1][1]*100,4), np.round(validation_results[-1][1]*100,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiBwg9mykWz5"
      },
      "source": [
        "#### Test the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksQw52S2kWz5",
        "outputId": "08bdd3b9-37c0-4b72-d41e-6549e0b4bb90"
      },
      "outputs": [],
      "source": [
        "test_results = val_test_loop(ds_test, batch_size, net, loss_fn)\n",
        "\n",
        "print(\"Test accuracy: {}%\".format(np.round(test_results[1]*100,4)))\n",
        "\n",
        "_, counts = np.unique(ds_test[:][1].cpu(), return_counts=True)\n",
        "most_frequent = counts[np.argmax(counts)]\n",
        "chance_level = most_frequent/len(ds_test)\n",
        "\n",
        "print(\"\\tChance level is {}%\".format(np.round(chance_level*100,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSn7XPNzkWz5"
      },
      "source": [
        "#### Single-sample inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "single_sample = next(iter(DataLoader(ds_test, batch_size=1, shuffle=True)))\n",
        "print(\"Randomly selected sample: {}\".format(letter_written_nir[single_sample[1].cpu()[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64rSRzIhkWz5",
        "outputId": "65a88823-f5dc-4530-9c5d-6c95295cc45e"
      },
      "outputs": [],
      "source": [
        "_, spk_out = val_test_loop(TensorDataset(single_sample[0],single_sample[1]), 1, net, loss_fn, return_spikes=True)\n",
        "pred = np.argmax(np.sum(spk_out, axis=0))\n",
        "\n",
        "### Plot output spiking activity\n",
        "spk_out = np.moveaxis(spk_out,1,2)\n",
        "spk_out = np.squeeze(spk_out, axis=-1)\n",
        "spk_out.shape\n",
        "aer = []\n",
        "for num,el in enumerate(spk_out):\n",
        "  addr = np.where(el)[0].tolist()\n",
        "  if len(addr) > 0:\n",
        "    for ii in addr:\n",
        "      aer.append([num,ii])\n",
        "aer = np.array(aer)\n",
        "\n",
        "plt.figure(figsize=(6,4.5))\n",
        "plt.scatter(aer[:,0], aer[:,1], s=1)\n",
        "plt.plot(range(0,spk_out.shape[0]),np.ones(spk_out.shape[0])*pred, '--', color=\"tab:red\", alpha=0.5)\n",
        "plt.xlabel(\"Timestep (a.u.)\")\n",
        "plt.ylabel(\"Output neuron\")\n",
        "plt.title(\"Output spiking activity (character: '{}', prediction: '{}')\".format(letter_written_nir[single_sample[1].cpu()[0]],letter_written_nir[pred]))\n",
        "plt.ylim(-0.5,int(len(letter_written_nir))-0.5)\n",
        "plt.yticks(range(int(len(letter_written_nir))))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw4Lp4rJkWz5"
      },
      "source": [
        "### Export the network to NIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCeKyxJHkWz6",
        "outputId": "1dd647a9-191a-4fcd-88a2-41531f0fdb8b"
      },
      "outputs": [],
      "source": [
        "nir_graph = export_nir.export_to_nir(net.to(\"cpu\"), ds_test[0][0].unsqueeze(dim=0).to(device))\n",
        "\n",
        "print('Nodes:')\n",
        "for nodekey, node in nir_graph.nodes.items():\n",
        "    print('\\t', nodekey, node.__class__.__name__)\n",
        "print('Edges:')\n",
        "for edge in nir_graph.edges:\n",
        "    print('\\t', edge)\n",
        "\n",
        "create_directory('./graphs')\n",
        "nir.write(f'./graphs/{model_name}.nir', nir_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuk_Ra9hkWz6"
      },
      "source": [
        "### [snnTorch -->] NIR --> Brian 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SduYTzGhkWz6"
      },
      "outputs": [],
      "source": [
        "def input_array_to_spike_list(input_array):\n",
        "    input_spikes = {}\n",
        "    spike_counts_s2 = 0\n",
        "    for i, row in enumerate(input_array):\n",
        "        input_spikes[i] = np.where(row == 1)[0].astype(int).tolist()\n",
        "        spike_counts_s2 += len(input_spikes[i])\n",
        "    return input_spikes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoJp_A13kWz6"
      },
      "outputs": [],
      "source": [
        "backend = \"brian2\"\n",
        "brian2_quantize_weights = True\n",
        "\n",
        "reset_method = s2_nir.ResetMethod.ZERO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC7-9aEfkWz6",
        "outputId": "f0672d73-b5a2-4781-b414-14d858d59e83"
      },
      "outputs": [],
      "source": [
        "nir_model = nir.read(f'./graphs/{model_name}.nir')\n",
        "\n",
        "print(\"nodes:\")\n",
        "for nodekey, node in nir_model.nodes.items():\n",
        "    print(\"\\t\", nodekey, node.__class__.__name__, node.input_type[\"input\"].dtype)\n",
        "print(\"edges:\")\n",
        "for edge in nir_model.edges:\n",
        "    print(\"\\t\", edge)\n",
        "\n",
        "s2_nir.add_output_to_node(\"lif1.lif\", nir_model, \"ouput_lif1\")\n",
        "\n",
        "cfg = s2_nir.ConversionConfig(\n",
        "    output_record=[\"spikes\"],\n",
        "    dt=0.0001,\n",
        "    conn_delay=0,\n",
        "    scale_weights=True,\n",
        "    reset=reset_method,\n",
        "    integrator=s2_nir.IntegratorMethod.FORWARD,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkPHFQiikWz6",
        "outputId": "913128c5-d554-4a0f-af41-99566d5d1b60"
      },
      "outputs": [],
      "source": [
        "net_brian, inp, outp = s2_nir.from_nir(nir_model, cfg)\n",
        "assert len(inp) == 1  # make sure there is only one input pop\n",
        "\n",
        "for pop in net_brian.populations:\n",
        "    if pop.name == \"lif1.lif\":\n",
        "        pop.set_max_atoms_per_core(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyVLGQ-bkWz6"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eXicsGBkWz6",
        "outputId": "ae9cbdad-5573-470a-b6de-0a912339b7dd"
      },
      "outputs": [],
      "source": [
        "n_samples = 50 #len(ds_test_enc)\n",
        "predicted_labels = []\n",
        "actual_labels = []\n",
        "\n",
        "my_loader = DataLoader(ds_test, batch_size=1, shuffle=True)\n",
        "\n",
        "for iteration, single_sample in enumerate(islice(my_loader, n_samples)):\n",
        "\n",
        "    print(f\"Sample {iteration+1}/{n_samples}:\")\n",
        "\n",
        "    sample = single_sample[0].numpy()\n",
        "\n",
        "    spike_times = input_array_to_spike_list(sample[0, :, :].T)\n",
        "\n",
        "    timesteps = sample.shape[1]\n",
        "    net_brian.reset()  # clear previous spikes and voltages\n",
        "\n",
        "    net_brian.populations[0].params = spike_times\n",
        "\n",
        "    hw = brian2_sim.Brian2Backend()\n",
        "    hw.run(net_brian, timesteps, quantize_weights=brian2_quantize_weights)\n",
        "\n",
        "    output_pop = next(p for p in outp if p.name == \"lif2\")\n",
        "    hidden_pop = next(p for p in outp if p.name == \"lif1.lif\")\n",
        "    spike_times = output_pop.get_spikes()\n",
        "\n",
        "    n_output_spikes = np.zeros(len(spike_times))\n",
        "    for nrn, spikes in spike_times.items():\n",
        "        n_output_spikes[nrn] = len(spikes)\n",
        "\n",
        "    print(f\"Total number of spikes per neuron: \\n\\t{n_output_spikes}\")\n",
        "    predicted_label = int(np.argmax(n_output_spikes))\n",
        "    actual_label = int(single_sample[1])\n",
        "    print(f\"Character: '{letter_written_nir[actual_label]}'\")\n",
        "    print(f\"Prediction: '{letter_written_nir[predicted_label]}'\\n\")\n",
        "    predicted_labels.append(predicted_label)\n",
        "    actual_labels.append(actual_label)\n",
        "\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "actual_labels = np.array(actual_labels)\n",
        "n_correct = np.count_nonzero(predicted_labels == actual_labels)\n",
        "print(f\"{n_correct} correct predictions out of {n_samples}\")\n",
        "print(f\"Test accuracy: {np.round(n_correct/n_samples*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPp3Y7w9kWz6"
      },
      "source": [
        "#### Single-sample inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubJHpAfBkWz7",
        "outputId": "7ded61f8-99dd-45a7-ed6d-ffa8169b02d0"
      },
      "outputs": [],
      "source": [
        "single_sample = next(iter(DataLoader(ds_test, batch_size=1, shuffle=True)))\n",
        "print(\"Randomly selected sample: {}\".format(single_sample[1].cpu()[0]))\n",
        "\n",
        "sample = single_sample[0].numpy()\n",
        "\n",
        "spike_times = input_array_to_spike_list(sample.squeeze(axis=0).T)\n",
        "\n",
        "timesteps = sample.shape[1]\n",
        "net_brian.reset()\n",
        "\n",
        "net_brian.populations[0].params = spike_times\n",
        "\n",
        "hw = brian2_sim.Brian2Backend()\n",
        "hw.run(net_brian, timesteps, quantize_weights=brian2_quantize_weights)\n",
        "\n",
        "output_pop = next(p for p in outp if p.name == \"lif2\")\n",
        "hidden_pop = next(p for p in outp if p.name == \"lif1.lif\")\n",
        "spike_times = output_pop.get_spikes()\n",
        "\n",
        "n_output_spikes = np.zeros(len(spike_times))\n",
        "for nrn, spikes in spike_times.items():\n",
        "    n_output_spikes[nrn] = len(spikes)\n",
        "\n",
        "print(f\"Total number of spikes per neuron: \\n\\t{n_output_spikes}\")\n",
        "predicted_label = int(np.argmax(n_output_spikes))\n",
        "actual_label = int(single_sample[1])\n",
        "\n",
        "spk_out = np.zeros((num_steps,int(len(letter_written_nir))))\n",
        "for ii in spike_times.keys():\n",
        "    spikes = np.zeros(num_steps)\n",
        "    spikes[spike_times[ii]] = 1.\n",
        "    spk_out[:,ii] = spikes\n",
        "aer = []\n",
        "for num,el in enumerate(spk_out):\n",
        "  addr = np.where(el)[0].tolist()\n",
        "  if len(addr) > 0:\n",
        "    for ii in addr:\n",
        "      aer.append([num,ii])\n",
        "aer = np.array(aer)\n",
        "\n",
        "plt.figure(figsize=(6,4.5))\n",
        "plt.scatter(aer[:,0], aer[:,1], s=1)\n",
        "plt.plot(range(0,spk_out.shape[0]),np.ones(spk_out.shape[0])*predicted_label, '--', color=\"tab:red\", alpha=0.5)\n",
        "plt.xlabel(\"Timestep (a.u.)\")\n",
        "plt.ylabel(\"Output neuron\")\n",
        "plt.title(f\"Output spiking activity (character: '{letter_written_nir[actual_label]}', prediction: '{letter_written_nir[predicted_label]}')\")\n",
        "plt.ylim(-0.5,int(len(letter_written_nir))-0.5)\n",
        "plt.yticks(range(int(len(letter_written_nir))))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vJsVu0H2FIol",
        "V0pq1QdFDEH9",
        "yWFH_RlnkWzw",
        "qQga4Aa7HaM1",
        "9pt39l4pvw3c",
        "ZRl5b02WkWz4",
        "ZISpcrO3JUGv"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.16 ('env_nce': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2e5f42e4452efdb55deabd82d647dd2921cc3aaae1fb4d0764999ca11e054984"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
